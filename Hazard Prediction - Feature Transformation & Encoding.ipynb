{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Hazard Ratings for a Maintenance Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hz_train = pd.read_csv(r'C:\\Users\\a.vijaykumar.satpute\\Documents\\Edvancer\\Project4\\Hazard_train.csv')\n",
    "hz_test = pd.read_csv(r'C:\\Users\\a.vijaykumar.satpute\\Documents\\Edvancer\\Project4\\Hazard_test_share.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Combine Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hz_train['data']='train'\n",
    "hz_test['data']='test'\n",
    "all_data=pd.concat([hz_train,hz_test],0,sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drop insignificant columns we identified in feauture selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(['Id','T1_V4', 'T1_V8','T1_V15','T1_V3','T1_V6','T1_V7','T1_V12',\n",
    "              'T1_V17','T2_V5','T2_V13', 'T2_V3','T2_V11','T2_V12',\n",
    "               'T1_V10','T1_V13','T2_V1','T2_V7','T2_V8','T2_V10'],\n",
    "              1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50999, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dummy encoding T1_V5 based on post hoc test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['T1_V5_A']=np.where(all_data['T1_V5'].str.contains(\"A\"), 1, 0)\n",
    "all_data['T1_V5_B']=np.where(all_data['T1_V5'].str.contains(\"B\"), 1, 0)\n",
    "all_data['T1_V5_C']=np.where(all_data['T1_V5'].str.contains(\"C\"), 1, 0)\n",
    "all_data['T1_V5_H']=np.where(all_data['T1_V5'].str.contains(\"H\"), 1, 0)\n",
    "all_data['T1_V5_K']=np.where(all_data['T1_V5'].str.contains(\"K\"), 1, 0)\n",
    "\n",
    "del all_data['T1_V5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dummy encoding T1_V9 based on post hoc test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['T1_V9_B']=np.where(all_data['T1_V9'].str.contains(\"B\"), 1, 0)\n",
    "all_data['T1_V9_D']=np.where(all_data['T1_V9'].str.contains(\"D\"), 1, 0)\n",
    "all_data['T1_V9_E']=np.where(all_data['T1_V9'].str.contains(\"E\"), 1, 0)\n",
    "\n",
    "del all_data['T1_V9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dummy encoding T1_V11 based on post hoc test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['T1_V11_A']=np.where(all_data['T1_V11'].str.contains(\"A\"), 1, 0)\n",
    "all_data['T1_V11_E']=np.where(all_data['T1_V11'].str.contains(\"E\"), 1, 0)\n",
    "\n",
    "del all_data['T1_V11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dummy encoding T1_V16 based on post hoc test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['T1_V16_A']=np.where(all_data['T1_V16'].str.contains(\"A\"), 1, 0)\n",
    "all_data['T1_V16_D']=np.where(all_data['T1_V16'].str.contains(\"D\"), 1, 0)\n",
    "\n",
    "del all_data['T1_V16']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Most of the numerical variables are count and are ordinal in nature, we will bin the data using qcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['T1_V1'] = pd.qcut(all_data['T1_V1'],5, duplicates='drop').cat.codes\n",
    "all_data['T1_V2'] = pd.qcut(all_data['T1_V2'],5, duplicates='drop').cat.codes\n",
    "all_data['T1_V14'] = pd.qcut(all_data['T1_V14'],3, duplicates='drop').cat.codes\n",
    "all_data['T2_V2'] = pd.qcut(all_data['T2_V2'],10, duplicates='drop').cat.codes\n",
    "all_data['T2_V4'] = pd.qcut(all_data['T2_V4'],5, duplicates='drop').cat.codes\n",
    "all_data['T2_V6'] = pd.qcut(all_data['T2_V6'],5, duplicates='drop').cat.codes\n",
    "all_data['T2_V9'] = pd.qcut(all_data['T2_V9'],5, duplicates='drop').cat.codes\n",
    "all_data['T2_V14'] = pd.qcut(all_data['T2_V14'],5, duplicates='drop').cat.codes\n",
    "all_data['T2_V15'] = pd.qcut(all_data['T2_V15'],7, duplicates='drop').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50999, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'transformed_all_data_hazard'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(all_data,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40799, 22), (10200, 21))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=all_data.drop('data',1)[all_data['data']=='train']\n",
    "test=all_data.drop(['data','Hazard'],1)[all_data['data']=='test']\n",
    "train.shape, test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
